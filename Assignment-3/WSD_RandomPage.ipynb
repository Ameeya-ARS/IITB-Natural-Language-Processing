{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK3voqcGiOne",
        "outputId": "6bca135f-192b-47e6-f383-df3849631fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('semcor')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.corpus import semcor\n",
        "import networkx as nx\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from sys import argv\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QNUPIBmyHaa",
        "outputId": "c74bd0df-4602-40df-f1de-134c682cb98b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1wAT_SkyadT"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model_w2v = KeyedVectors.load_word2vec_format('drive/MyDrive/CS626/Assignment_2/GoogleNews-vectors-negative300.bin',binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7lbLY8Hyujp"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "vectors = {}\n",
        "semcor_sents = semcor.sents()\n",
        "for sentence in semcor_sents:\n",
        "    for word in sentence:\n",
        "        if word in model_w2v:\n",
        "            vectors[word] = model_w2v.get_vector(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2md44LLzaVc"
      },
      "outputs": [],
      "source": [
        "def sent_vec(sentence):\n",
        "    li = []\n",
        "    for word in sentence:\n",
        "        if word in vectors:\n",
        "            li.append(vectors[word])\n",
        "    if len(li) == 0:\n",
        "        return np.zeros(300)\n",
        "    return np.average(li,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1G6kjBty-Nj"
      },
      "outputs": [],
      "source": [
        "def leskSim(sense1,sense2):\n",
        "  sent1 = [w for w in sense1.split()]\n",
        "  sent2 = [w for w in sense2.split()]\n",
        "  X = []\n",
        "  X.append(sent_vec(sent1))\n",
        "  X.append(sent_vec(sent2))\n",
        "  return cosine_similarity(X)[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psQRYhuZ_50S"
      },
      "outputs": [],
      "source": [
        "def edge_weight(g,sense,layer):\n",
        "    #lets pass a one sense of a word and the trailing layer.\n",
        "    #find the corresponding definations\n",
        "    def1 = wn.synset(sense).definition()\n",
        "    def2 = {}\n",
        "    for i in range(len(layer)):\n",
        "      try:\n",
        "            def2[i] = wn.synset(layer[i]).definition()\n",
        "      except ValueError:\n",
        "            print(layer)\n",
        "            break\n",
        "      edge_weight = leskSim(def1,def2[i])#pass two sense definitions\n",
        "      g.add_edge(sense,layer[i],weight=edge_weight)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvbunuTjAFL2"
      },
      "outputs": [],
      "source": [
        "def graph(sent1):#takes two sentence and generates wordsense graph\n",
        "    G = nx.Graph()\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    s1=tokenizer.tokenize(sent1)\n",
        "    dict1={}\n",
        "    \n",
        "    for i in range(len(s1)):\n",
        "        dict1[i] = [str(k.name()) for k in wn.synsets(s1[i])]  #all the word senses of i th word here \n",
        "\n",
        " \n",
        "    for i in dict1.keys():\n",
        "        G.add_nodes_from(dict1[i])\n",
        "        \n",
        "    #here all the nodes are added\n",
        "    #add the edges to it\n",
        "    for l in dict1.keys():\n",
        "        for senses in dict1[l]:\n",
        "            if l<(len(dict1)-1):           \n",
        "                edge_weight(G,senses,dict1[l+1])\n",
        "    return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tkoun75AHc1"
      },
      "outputs": [],
      "source": [
        "def get_Ranks(Graph):\n",
        "    rank = nx.pagerank(Graph,alpha=0.4)\n",
        "    return rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DupOJSFmAJ_d"
      },
      "outputs": [],
      "source": [
        "def senseAssignment(senseDict,Ranks):\n",
        "    SenseLst=[]\n",
        "    for word in senseDict:\n",
        "        maxRank=0\n",
        "        Sense=\"\"\n",
        "        for sense in senseDict[word]:\n",
        "          try:\n",
        "            if maxRank < Ranks[sense]:\n",
        "              maxRank = Ranks[sense]\n",
        "              Sense = sense\n",
        "          except:\n",
        "            pass\n",
        "        try:\n",
        "            SenseLst.append(wn.synset(Sense).name()) #For definition wn.synset(Sense).definition() \n",
        "        except:\n",
        "            SenseLst.append(\"notag\")\n",
        "    return SenseLst"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(sen):\n",
        "  sentence = ' '.join(sen)\n",
        "  G=graph(sentence)\n",
        "  ranks = nx.pagerank(G,alpha=0.4)\n",
        "  s1=sen\n",
        "  dict1={}\n",
        "  for i in range(len(s1)):\n",
        "    dict1[i] = [str(k.name()) for k in wn.synsets(s1[i])]  #all the word senses of i th word here\n",
        "\n",
        "  senseLst = senseAssignment(dict1,ranks)\n",
        "  senseLst_dict = dict()\n",
        "  for i in range(len(s1)):\n",
        "    senseLst_dict[s1[i]] = senseLst[i]\n",
        "  return senseLst_dict"
      ],
      "metadata": {
        "id": "vtv8YIJax2NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxtCvglfBRza"
      },
      "outputs": [],
      "source": [
        "result = prediction(['my','country','india'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmi1Denlovqj",
        "outputId": "a7f2fce3-14f5-4d05-9bee-d644cf28a931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'my': 'notag', 'country': 'nation.n.02', 'india': 'india.n.01'}\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDBDFhkxR6VI"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sense_dict(sents):\n",
        "    sense_set = set()\n",
        "    for i in range(len(sents)):\n",
        "        for j in range(len(sents[i])):\n",
        "            if isinstance(sents[i][j], nltk.Tree):\n",
        "                try :\n",
        "                    if sents[i][j].height() == 3:\n",
        "                        for tree in sents[i][j]:\n",
        "                            if(tree.label() == 'NE'):\n",
        "                                sense = 'NE'\n",
        "                                sense_set.add(sense) \n",
        "                    else :\n",
        "                        sense = sents[i][j].label().synset().name()\n",
        "                        sense_set.add(sense)\n",
        " \n",
        "                except:\n",
        "                    if(sents[i][j].label() == 'NE'):\n",
        "                        sense = sents[i][j].label()\n",
        "                        sense_set.add(sense)\n",
        "                    else :\n",
        "                        sense = sents[i][j].label()\n",
        "                        sense_set.add(sense)\n",
        "            else :\n",
        "                sense = 'notag'\n",
        "                sense_set.add(sense)\n",
        "    sense_set.add('unk')\n",
        "    sense_set = list(sense_set)\n",
        "    sense_dict = {sense : i for i, sense in enumerate(sense_set)}\n",
        "    return sense_dict"
      ],
      "metadata": {
        "id": "P58bBh8Ez039"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sents, untagged_sents):\n",
        "    pred_sense = []\n",
        "    actual_sense = []\n",
        "    for i in range(len(sents)):\n",
        "        temp = prediction(untagged_sents[i])\n",
        "        for j in range(len(sents[i])):\n",
        "            if isinstance(sents[i][j], nltk.Tree):\n",
        "                try :\n",
        "                    if sents[i][j].height() == 3:\n",
        "                        for tree in sents[i][j]:\n",
        "                            if(tree.label() == 'NE'):\n",
        "                                sense = 'NE'\n",
        "                                actual_sense.append(sense)\n",
        "                                word = \"_\".join(tree.leaves())\n",
        "                    else :\n",
        "                        sense = sents[i][j].label().synset().name()\n",
        "                        actual_sense.append(sense)\n",
        "                        word = \"_\".join(sents[i][j].leaves())\n",
        "                    pred_sense.append(temp.get(word,'notag'))                  \n",
        "                except:\n",
        "                    if(sents[i][j].label() == 'NE'):\n",
        "                        sense = sents[i][j].label()\n",
        "                        word = \"_\".join(sents[i][j].leaves())\n",
        "                        actual_sense.append(sense)\n",
        "                    else :\n",
        "                        sense = sents[i][j].label()\n",
        "                        word = \"_\".join(sents[i][j].leaves())\n",
        "                        actual_sense.append(sense)\n",
        "                    pred_sense.append(temp.get(word,'notag'))                \n",
        "            else :\n",
        "                sense = 'notag'\n",
        "                actual_sense.append(sense)\n",
        "                word = \"_\".join(sents[i][j])\n",
        "                pred_sense.append(temp.get(word,'notag'))          \n",
        "    return actual_sense, pred_sense"
      ],
      "metadata": {
        "id": "Jth-YaMnxs0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sents = semcor.tagged_sents(tag='sem')\n",
        "sense_dict = get_sense_dict(sents)\n",
        "untagged_sents = semcor.sents()\n",
        "y_true, y_pred = predict(sents, untagged_sents)\n",
        "\n",
        "y_true = [sense_dict[sense] for sense in y_true]\n",
        "y_pred = [sense_dict.get(sense, sense_dict['notag']) for sense in y_pred]"
      ],
      "metadata": {
        "id": "sS93Cwbkxw44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_map = {v: k for k, v in sense_dict.items()}\n",
        "y_true = [inv_map[i] for i in y_true]\n",
        "y_pred = [inv_map[i] for i in y_pred]\n",
        "y_true_n, y_pred_n = [],[]\n",
        "for i in range(len(y_true)):\n",
        "  if(y_true[i] != 'notag' and y_true[i] != 'NE'):\n",
        "    temp = y_true[i].split('.')[1]\n",
        "    if(temp=='n'):\n",
        "      y_true_n.append(y_true[i])\n",
        "      y_pred_n.append(y_pred[i])"
      ],
      "metadata": {
        "id": "UuS1yDD0G7Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy : \", metrics.accuracy_score(y_true_n, y_pred_n))\n",
        "precision, recall, f1score, _ = metrics.precision_recall_fscore_support(y_true, y_pred, average='weighted',zero_division=0)\n",
        "print(\"Precision : \", precision)\n",
        "print(\"Recall : \", recall)\n",
        "print(\"F1 Score : \", f1score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YQ0IkZz0CY3",
        "outputId": "40dff6b0-cbca-4780-dbaa-c97af102fbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.3798242406667255\n",
            "Precision :  0.6994952164393669\n",
            "Recall :  0.5876234768882604\n",
            "F1 Score :  0.621535092767554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"She is a government servant\"\n",
        "tokens = word_tokenize(test_sentence)\n",
        "pred_dict = prediction(tokens)\n",
        "for x,y in pred_dict.items():\n",
        "  if(y!='notag'):\n",
        "    print(\"Target Word : \" + x + \"\\nPredicted Sense : \" + y + \" : \" + wn.synset(y).definition() + \"\\n\")\n",
        "  else:\n",
        "    print(\"Target Word : \" + x + \"\\nPredicted Sense : \" + y + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjosxjSAlWBR",
        "outputId": "3d189c2d-19fd-4b55-d29c-6b756ef596be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Word : She\n",
            "Predicted Sense : notag\n",
            "\n",
            "Target Word : is\n",
            "Predicted Sense : be.v.12 : to remain unmolested, undisturbed, or uninterrupted -- used only in infinitive form\n",
            "\n",
            "Target Word : a\n",
            "Predicted Sense : deoxyadenosine_monophosphate.n.01 : one of the four nucleotides used in building DNA; all four nucleotides have a common phosphate group and a sugar (ribose)\n",
            "\n",
            "Target Word : government\n",
            "Predicted Sense : government.n.03 : (government) the system or form by which a community or other political unit is governed\n",
            "\n",
            "Target Word : servant\n",
            "Predicted Sense : servant.n.01 : a person working in the service of another (especially in the household)\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}